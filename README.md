# ğŸ§  PDF Data Extractor com GPT-5-mini

- Um sistema assÃ­ncrono e escalÃ¡vel para extraÃ§Ã£o estruturada de dados a partir de PDFs, utilizando *producers* e *consumers* paralelos, e integraÃ§Ã£o com o modelo **GPT-5-mini**.    
- O pipeline Ã© monitorado em tempo real por uma interface grÃ¡fica reativa, que exibe progresso, e a resposta em conforme vai sendo processado.  
- A integraÃ§Ã£o tem todas as bibliotecas sendo multi-plataforma mas apenas foi testada em Linux e Windows.  
- OBS: para usuÃ¡rios MAC nÃ£o deve apresentar problemas mas talvez algumas configuraÃ§Ãµes internas possam atrapalhar o desempenho ou UI. 
---

## âš™ï¸ VisÃ£o Geral

O projeto Ã© composto por **trÃªs camadas principais**:

1. **ğŸ–¥ï¸ Interface GrÃ¡fica (UI)** â€“ onde o usuÃ¡rio inicia o processo, acompanha o progresso e visualiza os resultados.
2. **âš™ï¸ NÃºcleo de Processamento (CORE)** â€“ orquestra produtores e consumidores que interagem com o modelo de IA.
3. **ğŸ§  GPT-5-mini** â€“ responsÃ¡vel por interpretar o texto extraÃ­do dos PDFs e retornar o JSON padronizado com os campos definidos.

---

## ğŸ§© Arquitetura do Sistema

```mermaid
flowchart TD

%% === Interface ===
subgraph UI["ğŸ’» Interface GrÃ¡fica"]
    UI1["â–¶ï¸ InÃ­cio"]
    UI2["ğŸš€ Executa Extractor"]
    UI3["ğŸ‘€ Monitora progresso"]
    UI4["ğŸ“Š Atualiza status em tempo real"]
end

%% === NÃºcleo de Processamento ===
subgraph CORE["âš™ï¸ NÃºcleo de Processamento"]
    subgraph PROD["ğŸ§  Produtores"]
        P1["ğŸ“„ Ler PDFs"]
        P2["ğŸ§© Criar prompts GPT"]
        P3["ğŸ“¤ Enviar para fila"]
    end

    subgraph CONS["ğŸ” Consumidores"]
        C1["ğŸ“¥ Receber resposta GPT"]
        C2["ğŸ§¾ Validar e processar"]
        C3["ğŸ’¾ Salvar JSON final"]
    end
end

%% === Modelo ===
subgraph MODEL["ğŸ§¬ GPT-5-mini"]
    M1["ğŸ“¨ Recebe prompt"]
    M2["ğŸ“¬ Retorna JSON extraÃ­do"]
end

%% === Fluxo principal ===
UI1 --> UI2
UI2 --> P1
P1 --> P2
P2 --> P3
P3 --> M1
M1 --> M2
M2 --> C1
C1 --> C2
C2 --> C3
C3 -->|ğŸŸ¡ Atualiza progresso| UI3
UI3 --> UI4

%% === Ciclos internos ===
P3 -->|â™»ï¸ Enquanto houver PDFs| P1
C3 -->|ğŸ”„ Ainda hÃ¡ respostas| C1
P3 -->|âœ… ApÃ³s produÃ§Ã£o| CONS
CONS -->|âš™ï¸ Reitera se pendente| C1

```
## ğŸ” Fluxo de ExecuÃ§Ã£o

    O usuÃ¡rio inicia o processo na interface e seleciona os PDFs.

    A UI chama a funÃ§Ã£o Extractor, que inicializa N produtores e M consumidores.

    Cada produtor:

        LÃª um arquivo PDF.

        Gera o prompt no formato esperado pelo modelo.

        Envia o prompt para uma fila assÃ­ncrona.

    O modelo GPT-5-mini processa os prompts e retorna o JSON com os campos extraÃ­dos.

    Os consumidores:

        Leem as respostas do modelo.

        Validam e limpam os dados.

        Salvam os resultados em um arquivo final (respostas.json).

        Repetem o ciclo enquanto houver itens na fila.

    A UI monitora continuamente o arquivo json/result.json e atualiza o progresso em tempo real.

## ğŸ§° Tecnologias Utilizadas  
- Python 3.11+	Base da aplicaÃ§Ã£o  
- asyncio / threading	Gerenciamento paralelo de produtores e - consumidores  
- GPT-5-mini API	ExtraÃ§Ã£o inteligente de dados dos textos  
- PyQt6 Interface grÃ¡fica  

## ğŸš€ ExecuÃ§Ã£o
1. InstalaÃ§Ã£o das dependÃªncias

    `pip install -r requirements.txt`
2. FaÃ§a um arquivo .env com a sua chave API da open-ai
    `OPENAI_API_KEY="SUA_CHAVE_AQUI"`
3. ExecuÃ§Ã£o normal (com UI)

    `python3 main.py`

4. Selecione os pdf que queira ler pode ser tanto selecionando os pdf quanto a pasta em que eles estÃ£o e qual schema.json quer usar ( default: dataset.json ) 
 
5. Resultado

    Arquivo de saÃ­da: json/result.json ou na interface grÃ¡fica

## ğŸ’¡ CaracterÃ­sticas AvanÃ§adas

    ğŸš€ Interface grÃ¡fica com Resposta atualizada para o cliente ter noÃ§Ã£o do que estÃ¡ acontecendo

    âœ… Produtores se transformam automaticamente em consumidores quando terminam suas tarefas para maximizar eficiÃªncia.

    ğŸ”„ Loops contÃ­nuos atÃ© o esvaziamento completo das filas.

    âš¡ Processamento paralelo otimizado.

    ğŸ§© Modular e expansÃ­vel â€” fÃ¡cil adicionar novos documentos.

    ğŸ“¡ ComunicaÃ§Ã£o assÃ­ncrona entre componentes.

## ğŸ§‘â€ğŸ’» Estrutura de Pastas
ğŸ“ projeto/  
â”œâ”€â”€ main.py  
â”œâ”€â”€ extractor.py  
â”œâ”€â”€ test/ # this folder is for developer test's only  
â”‚   â”œâ”€â”€ func_test.py  
â”‚   â””â”€â”€ gabarito.json  
â”œâ”€â”€ json/  
â”‚   â”œâ”€â”€ pdfs/  
â”‚   â”œâ”€â”€ dataset.json  
â”‚   â”œâ”€â”€ files_to_process.json  
â”‚   â””â”€â”€ respostas.json 
â”œâ”€â”€ .env  
â””â”€â”€ README.md  
## ğŸ§  Processo de Desenvolvimento

Durante o desenvolvimento deste projeto, meu foco foi entender o problema e dividi-lo em etapas bem definidas:

1. **Interface (UI)** â€“ Criei uma interface simples e funcional para interagir com o processo.  
2. **FormataÃ§Ã£o do Prompt** â€“ Estruturei o texto de entrada para garantir que a IA recebesse as informaÃ§Ãµes da forma mais eficiente possÃ­vel.  
3. **Envio Ã  IA** â€“ Implementei a comunicaÃ§Ã£o com o modelo, garantindo consistÃªncia entre as chamadas.  
4. **Cache de Resultados** â€“ Adicionei cache para evitar repetiÃ§Ãµes desnecessÃ¡rias e otimizar custos.  
5. **FormataÃ§Ã£o da Resposta** â€“ Estruturei a saÃ­da para anÃ¡lise posterior e testes de validaÃ§Ã£o.  

Na **reuniÃ£o de terÃ§a-feira**, descobri que o processo poderia ser **assÃ­ncrono** des de que a primeira resposta chegasse em menos de 10s, o que me levou a pensar em um **modelo de produtor e consumidor** para maximizar a eficiÃªncia.  
Fui testando para o meu sistema e percebi que conseguia uma quantidade grande de consumidores sem risco de falhar na minha infraestrura pessoal que Ã© bem bÃ¡sica entÃ£o ficou tÃ£o rÃ¡pido que precisei **ampliar a base de dados de PDFs** â€” fazendo ele processar **6 arquivos, 200 vezes cada**, mantendo o mesmo consumo de tokens por chamada.  

PorÃ©m, como o cÃ³digo estava processando em poucos lotes de chamada o cache acabou apenas **aumentando o tamanho do prompt**, decidi **removÃª-lo** para simplicar e diminuir a quantidade de tokens de entrada e focar na velocidade pura do processamento.  

Por fim, criei uma **funÃ§Ã£o de teste** para validar a **acurÃ¡cia dos resultados**, garantindo que o texto final estivesse coerente e bem gerado.

## ğŸ§© Desafios encontrados

As requisiÃ§Ãµes jÃ¡ estavam bem econÃ´micas e rÃ¡pidas, entÃ£o o prÃ³ximo passo foi buscar formas de aumentar a eficiÃªncia geral, mesmo com o tempo fixo de cada chamada Ã  API.

A soluÃ§Ã£o foi implementar um modelo de produtor e consumidor assÃ­ncrono, permitindo processar mÃºltiplos PDFs em paralelo e atualizar os resultados em tempo real.

AlÃ©m disso, busquei otimizar cada etapa â€” desde a leitura dos PDFs com o PyMuPDF (fitz) atÃ© o cache e escrita incremental dos resultados â€” sempre priorizando bibliotecas focadas em velocidade e baixo overhead.
## ğŸ§‘â€ğŸ“ Autor

Desenvolvido por **Gabriel Saboya**
